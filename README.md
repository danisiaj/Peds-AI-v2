# **RAG Langchain Model with OpenAI API** 

## _Project Overview_
This repository contains the code and documentation for a Project that incorporates different data science and ML strategies, addidng additional Generative AI features:
* MySQL: The app includes a page where the user can apply certain filters and build a dataframe using a sql query
* ML model: Images Classificator using HaggingFace model, where user can upload an image of a patient's wound, and the app return the type of wound (e.g.: pressure injury)
* Retrieval Augmented Generation (RAG) model: This model enables users to upload a PDF document, ask questions, and receive coherent, complete, and relevant responses generated by an integrated large language model (LLM).
* Streamlit app: Models deployes in Streamlit interface to enhance user experience
The RAG model dynamically generates a prompt from the user's query, incorporating instructions, context, and restrictions to create specific, contextually aware responses.


### _Content_
* The uploaded PDF is a 452-page document containing information on Pediatric Cardiology. Source: Pediatric Cardiology: Essential Pocket Guide, book.
* Dataset with 200 datapoints and 20 features containing information about the nursing crew (personal information, workplace information and education certifications.)

### _RAG Model Architecture_
#### Model Selection
The model architecture is centered around OpenAIEmbeddings API as the text transformer. Key libraries used include:

* OpenAI: for embeddings and LLM
* Langchain: For text extraction and model chaining.
* Qdrant: To create and manage the vector store.

#### Components
* Document Loader: pdfplumber handles document uploads and text parsing.
* Embeddings: OpenAIEmbeddings transforms text into vector representations.
* Text Extraction: RecursiveTextCharacterSplitter and Qdrant handle text processing and vectorization.

### _Chain Architecture_
### * _Retrieval of Information_: 
User queries retrieve a set of k documents (where k=5 in the code) from the Qdrant vector store using similarity_search().
### * _Prompt Engineering_:
* A context is built using the selected documents.
* This context is passed to the dynamic prompt-generating function.
* A specific, context-aware prompt is created based on the userâ€™s query.
### * _LLM Implementation_: 
The prompt is sent to the LLM via the OpenAI API to generate the desired response.
### _Model Evaluation_
A second LLM model is used as a "judge" to evaluate the generated responses based on the following criteria:

 * Relevance(0-5)
 * Accuracy(0-5)
 * Completeness(0-5)
 * Clarity(0-5)

Through prompt engineering, a dedicated evaluation prompt is used to assess the quality of each response.

### _ML Model Architecture_
* HaggingFace: for image classification

### _Streamlit App Architecture_
The model is deployed on a multipage Streamlit app, providing a user-friendly interface. Users can upload their our document, input questions and receive responses formatted in Markdown, followed by the LLM-based evaluation. This design also allows user to upload images of their patients to have a better idea of what type of wounds they are delaling with.
* Home page: log in required to access the app features (secure system)
* Peds AI: users can access information about certain documents (Pediatric Cardiology in this case)
* Education Center: Integrated SQL queries allow users to access information about the whole team, and also see what kind of questions are being asked to the Peds AI to further evaluate the need to review certain topics. 
* Wound Classificator: users can upload an image of their patient's wound to have a better understanding of the care needed.

### _Conclusions_
Conclusion 1: The RAG model demonstrated high efficiency in terms of response time and relevance to user queries.
Conclusion 2: The Image classificator offers a limited service, since it was not possible to retrain on a different set of images due to difficulty to find images of wounds (the goal is to determine is the wounds are infected)
Conclusion 3: The Education Center page offer limitless possibilities to retrieve data from the nurses dataset, allowing the user to manage and target the needs for further educational programs and review courses for the nurses. 

### _Repository_
* Data folder: pdf and csv documents
* main.py where all the code is organized
* Pptx presentation
* ReadMe.md
* Requirements.txt with all the neccessary libraries for this project
* Streamlit folder ('pages') to deploy the code in Streamlit platform and test it in an application
* Tableau Dashboard link: https://public.tableau.com/app/profile/dani.siaj/viz/Book1_17310642525580/Dashboard1?publish=yes